%
% main.tex -- Paper zum Thema fpga
%
% (c) 2019 Hochschule Rapperswil
%

%TODO IMPORTANT! CHange picture path to match buch.tex!!!!

\graphicspath{papers/fpga/}

\chapter{FPGA Implementation der schnellen Wavelet-Transformation\label{chapter:fpga}}
\lhead{FPGA Implementation der schnellen Wavelet-Transformation}
\begin{refsection}
\chapterauthor{Jonas Gr√ºndler und Nicolas Tobler}

\section{Introduction}
\rhead{Introduction}

VHDL, an acronym for Very High Speed Integrated Circuit Hardware Description Language is commonly used to implement fast, aplication-specific logic for an FPGA or custom silicon chip.
As every other programming language VHDL relies heavily on reuse of code.
Blocks of contained code can be stored as a semiconductor intellectual property core (IP core) and reused for further applications.
A often used IP core is the Fast Fourier Transform (FFT), which is available online for free.
Discrete wavelet transforms, however are not that common.
Therefore, we have committed ourselfs to implement a wavelet transform as a hardware block in VHDL

A hardware implemented wavelet algorithm has many advantages over a software implementation.
First, arithmetic operations in hardware are much faster than in software.
While a CPU is bond to its limited instruction set.
A custom hardware can execute multiple operations of choice in one clock cycle.
Some of operations can be executed in parallel in order to gain even more spped.
Secondly, if stream based processing is implemented, which continuously processes incoming data, the latency is significantly lower.
This property makes hardware superior for real time applications.

In the first part, this work covers the theory of an efficient algorithm for the discrete wavelet transform.
Then, the implementation of this algorithm in VHDL is described.

%Ready for deletion
%If you try to transform and modify audio signals, which are sampled with 44 kHz you get, because of the clock speed of the FPGA, which is about 100 MHz, over 1000 arithmetic operations for every audio sample.
%In the next few pages we guide through the theory used, some design considerations and at last through our steps of developing a basic but functional Wavelet Transformation in VHDL. 


\section{Dicrete Wavelet Transform}
\rhead{Lifting Scheme}

The discrete wavelet transform is covered in detail in chapter \ref{section:schnelle-synthese} of the script.
This section provides a short summary, as well as some additions, notably the Lifting Scheme.

%makes use of the multiresolution analysis %TODO add ref to script

the wavelet transform calculates the coefficients $a_{j,k}$ and $b_{k,k}$ from an input signal or coefficient $a_{j+1,k}$.

this operation can be cascaded

%TODO Nic stopped here


\begin{equation}
	x_t = a_{0,t}
\end{equation}

\begin{figure}
	\centering
	\input{papers/fpga/tikz/dwt.tikz}
	\caption{Discrete Wavelet transform and inverse transform}
\end{figure}


\subsection{Lifting Scheme}
\rhead{Lifting Scheme}

The lifting scheme is a technique to perform a discrete wavelet transform.
It is an widely used algorythm, which is more efficient in termes of multiplication uses than normal Wavelet Transformations.
It reduces the number of arithmetic operations nearly by a factor of two compared to a ordinary, convolutional algorithm. %TODO check convolutional
The lifting scheme was introduced in a paper from Ingrid Daubechies and Wim Sveldens \cite{fpga:Daubechies1998}. 

The Lifting Scheme factorizes any discrete wavelet transform with finite filters into a series of elementary covolutions (Lifting Steps).

This decomposition is equivalent to a factorization of the polyphase matrix of the wavelet filter into elementary matrices. 
In order to describe the underlying wavelet filters, the z-transform notation is used.
The z-transform of a FIR (finite impulse response) filter \textit{\textbf{h}} is a Laurent polynomial given by
\begin{equation}\label{equ:impulse}
	H(z) = \sum h_k z^{-k}
\end{equation}


\subsubsection{Polyphase Decomposition \label{fpga:polyphase}}

In our case we subsample the input signal by a factor of two.
This corresponds to splitting the signal into two sub channels (even and odd samples).
The polyphase decomposition is a algebraic way of describing the filter in matrices.
The polyphase components are the filter components of the sub channels. 
We can separate equation \ref{equ:impulse} into its even- and odd-indexed terms
\begin{equation}
	H(z) = \sum_{n=-\infty}^{\infty} h(2n)z^{-2n} + z^{-1} \sum_{n=-\infty}^{\infty} h(2n+1)z^{-2n}
\end{equation}
Following this scheme the polyphase components of the filter are defined as follows
\begin{equation}
E_0(z) = \sum_{n=-\infty}^{\infty} h(2n)z^{-n}
\end{equation}
\begin{equation}
E_1(z) = \sum_{n=-\infty}^{\infty} h(2n+1)z^{-n}
\end{equation}
which corresponds to the even and odd filter components.
Now $H(z)$ can be written in terms of the polyphase components
\begin{equation}
H(z)=E_{0}(z^2)+z^{-1} E_1(z^2)
\end{equation}
These coefficients are then placed in the so called Polyphase Matrix.
\begin{equation}
	P(z) = 
	\begin{bmatrix}
	h_e(z) & g_e(z) \\
	h_o(z) & g_o(z)
	\end{bmatrix}
\end{equation}

\begin{figure}
	\centering
	%\includegraphics[width=\textwidth]{./images/lifting_step_wavelet.pdf}
	\input{papers/fpga/tikz/liftingStep.tikz}
	\caption{Wavelet transformation with Lifiting Steps \label{fpga:lstp_wavelet}}
\end{figure}
Where $h_e(z)$ are the even- and $h_o(z)$ are the odd coefficients of the low pass filter.
$g(z)$ is the corresponding high pass filter. 
Because of its simplicity we first choose the Haar Wavelet.
In z notation $g(n)$ are the Father Wavelet coefficients whereas $h(n)$ are the corresponding Mother Wavelet coefficients. 
\begin{equation}
{\mathcal {Z}} \{h(n)\} = 1 + z^{-1}
\end{equation}
\begin{equation}
{\mathcal {Z}} \{g(n)\} = 1 - z^{-1}
\end{equation}
If we split these coefficients into even and odd components and fill them into the Polyphase Matrix we get 

\begin{equation*}
P(z) =
\begin{bmatrix}
1 & -\frac{1}{2} \\
1 & \frac{1}{2}
\end{bmatrix}
 = 
 \begin{bmatrix}
 1 & 0 \\
 1 & 1
 \end{bmatrix}
 \cdot
 \begin{bmatrix}
 1 & -\frac{1}{2} \\
 0 & 1
 \end{bmatrix}
\end{equation*}

The term on the right side is a possible factorization which results in lifting steps.
This factorizations produces diagonal matrices which are easy to compute and are the lifting steps.
This corresponds to the following implementation of the forward transform \cite{fpga:Daubechies1998}.
\begin{equation}\label{fpga:equation:haar}
	\begin{aligned}
	s_l^{(0)} &= x_{2l} \\
	d_l^{(0)} &= x_{2l+1} \\ 
	d_l &= d_l^{(0)} - s_l^{(0)} \\
	s_l &= s_l^{(0)} + \frac{1}{2}d_l
	\end{aligned}
\end{equation}
where $x_{n}$ is the incoming sample stream.
The analysis side is in the following form:
\begin{equation*}
P(z^{-1})^ =
\begin{bmatrix}
\frac{1}{2} & \frac{1}{2} \\
-1 & 1
\end{bmatrix}
= 
\begin{bmatrix}
1 & \frac{1}{2} \\
0 & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
1 & 0 \\
-1 & 1
\end{bmatrix}
\end{equation*}
In this case the inverse transformation is 
\begin{equation}\label{fpga:equation:inv_haar}
\begin{aligned}
s_l^{(0)} &= s_l - \frac{1}{2}d_l \\
d_l^{(0)} &= d_l + s_l \\ 
x_{2l+1}& =d_l^{(0)} \\
x_{2l} &= s_l^{(0)}
\end{aligned}
\end{equation}
and the original stream can be fully recovered.
In the next section we try to implement this algorithm in VHDL.

\section{Implementation}

\subsection{Design Considerations}

When implementing an algorithm in hardware, a lot of design considerations must be made in advance.
The hardware architecture is very dependent of the application.
A hardware block can be optimized for various points, such as high accuracy, low latency, high data rate, low area and low power consumption.
Since this work is not based on a defined objective, we must come up with our own design specifications.

In most cases, which do not require low latency and high data rates, a digital signal processor would be a better choice than a custom VHDL-implemented hardware.
A sequential processor unit is computationally very efficient and requires almost no area compared to most VHDL solutions.
However, it features a significantly higher latency.
Hence, the implementation should feature low latency and high data rate as its main objectives in order to provide a VHDL solution, that is actually reasonable.
The application should make use of on of the biggest advantages of custom hardware, which is parallelism.
Performing calculations in parallel leads to higher throughput and allows data rates which are as fast as the clock speed of the logic.
The strengths of the aspired implementation are thus high speed and low latency processing, suitable for real-time applications.

%TODO \texttt{haar} blocks are independent and can be parallelized

\subsection{Idea}

Two hardware blocks need be implemented for both forward wavelet and inverse wavelet transform.
The forward algorithm has a 16-bit signed number input and outputs a given number of wavelet coefficients as a stream.
This number can be specified with a generic parameter.

Each multiresolution analysis 

The main priority is to implement the Haar wavelet.
A optional goal is the implementation of a higher order wavelet, such as the orthogonal Daubechies-4 wavelet.
Another design element is to realize the structure as generalized as possible.
This because, if well implemented, it should be later easy to just change the transformation block to do transformations with other wavelets.


\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{papers/fpga/images/idea.pdf}
	\caption{Outline of the modules \label{fpga:idea}}
\end{figure}


\subsection{Architecture}
The VHDL hardware consists of three main blocks, as depicted in figure \ref{fpga:fig:architecture}.
These blocks do the forward transformation, branching, delaying and finaly the inverse transformation.
The following sections cover the different building blocks in detail. 
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{papers/fpga/images/main_delay.pdf}
	\caption{Complete architecture \label{fpga:fig:architecture}}
\end{figure}
\subsubsection{Forward and backward transformation}

The transformation block \texttt{haar} implements the algorithm needed for the wavelet transformation.
In the case of the Haar wavelet the fairly simple sequence described in equation \ref{fpga:equation:haar}.
It takes a 16-bit number as its input which is processed when the associated ready signal is driven high.
If this ready signal is always driven high, the input value is sampled each clock cycle.
The outputs consist of an array of wavelet coefficients, each of 16 bits, which are accompanied with a vector of ready signals. 

The inverse wavelet transform \texttt{inv\_haar} has an analogous outline.
The blocks are fed with the different coefficients and they get processed by the algorithm defined in equation \ref{fpga:equation:inv_haar}.
In this process the input coefficients are reconstructed to a 16-bit signed output number.% in the \texttt{inv\_branching} block, which holds several blocks of inverse wavelet transforms.

Because of the generalized structure and of VHDL in general this blocks can be adapted to different algorithms to perform transformations with different wavelets.



%TODO make figure of delay

\subsubsection{Branching}

The before mentioned transform is not very interesting. On the other hand, what would be challenging to implement is a recursive use of these blocks to get further coefficients of different frequencies.
So the upper mentioned process contains multiple wavelet-blocks which together perform a multiresolution analysis.
Since each layer splits a input data stream in half, this block is called \texttt{braching}.
The Lowpass output ($s$) samples of a Haar block are connected to another Haar block which does another transformation to get more detail. 
Because of this we need the also delayed ready signal from the last block because these coefficients are changing with half of the speed now. 
The inverse branching is then used to reconstruct the original signal from all the different transformations and coefficients.

\subsubsection{Delay}

Finally a third block is needed to delay the coefficients.
The wavelet transform is very expensive to calculate in one single clock cycle.
In order to provide low-latency regardless, a compromize has been made, which tolerates a delay of one cyle in each layer of the muliresolution analysis.
Because of this one clock cycle of delay in the transformation block the faster coefficients need to be artificially delayed.
If not they arrive to early at the inverse transformation and the result is faulty. To compensate this the   faster signals get delayed according to de depth of the recursion tree.
The coefficients containing the lowest frequencies stay the same and then for every step up on the recursion tree the delay gets one clock cycle longer.
With this processing the coefficients with belong together arrive at the inverse transformation at the same time.

%The coefficients except the one with the lowest frequency must be delayed for the inverse algorithm.



\subsection{Testing}

The test structure contains the forward transform, followed by the inverse transform, which should recover the original signal from the processed coefficients.
The depth of the branching and the recursion can be set by a variable. 
The test setup is shown in figure \ref{fpga:fig:testing}
If done right, the output should resemble the input, delayed by the latency of the whole pipeline.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{papers/fpga/images/vhdl_sim.pdf}
	\caption{Testing Workflow \label{fpga:fig:testing}}
\end{figure}

Vivado Toolchain from Xilix has been used to simulate the VHDL modules.
The wavelet transforms have also been implemented numerically identical in MATLAB in order to provide a direct comparison. 
A set of helper modules have been implemented in VHDL 2008, which are able to read and write test vectors and results from or to a file.
These modules provide an an easy way to inject test data from the MATLAB enviroment.
After the VHDL simulation finishes, the results are again fed into MATLAB for validation.

\section{Results}
\rhead{Results}

The results are promising. The results of the Vivado Toolchain and MATLAB match up. 
In picture \ref{fpga:fig:coeff} the coefficients and ready signals before delaying are depicted.
The delay of the ready signals, stepping into the recursion tree, gets doubled every step. 
And the wavelet coefficients are also plotted in different colors. 
The faster changing signals correspond to the higher frequencies and the slow changing signals are deeper in the recursion.
The higher frequencies also react faster to changes at the input.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{papers/fpga/images/coefs.pdf}
	\caption{Coefficients and ready signals after transformation \label{fpga:fig:coeff}}
\end{figure}

Picture \ref{fpga:fig:coeff_delayed} shows the coefficients and ready signals after delaying. 
As visible the coefficients start to change now delayed only by clock cycle. 
Like this there is no misalignment in the time domain and when they are transformed back the original signal is recovered. 
The ready signal illustrates this. 
Before the delaying the ready signal of the fast coefficients was first and the slower ones where delayed. 
But in reality the slower frequencies change at the same moment as the higher frequencies. 
And also the information from the high frequencies is also needed at the moment when the inverse transformation starts. 
So after the delaying the slow ready signal arrives first and then with every clock cycle the faster readys arrive. 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{papers/fpga/images/output.pdf}
	\caption{Output \label{fpga:fig:output}}
\end{figure}

Figure \ref{fpga:fig:output} shows the final result of the whole pipeline, As expected the signal is the same but delayed by the time the processing needed. 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{papers/fpga/images/coefs_delayed.pdf}
	\caption{Coefficients and ready signals after delaying \label{fpga:fig:coeff_delayed}}
\end{figure}

Also interesting is how the coefficients and signals look inside the simulation (figure \ref{fpga:fig:coefficients}). 
In a screenshot the coefficients of all recursive steps are visible. 
There is clearly visible, that the signal losses information in de deeper stages. 
This is because every step the detail information (higher frequencies) get subtracted and only the low frequencies stay.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{papers/fpga/images/inv_branching_screenshot.png}
	\caption{Coefficients in simulation \label{fpga:fig:sim}}
\end{figure}

\newpage

%The idea is to have a data stream \texttt{x} an a ready \texttt{rdy} signal. The ready signal indicates when the input from the data stream is valid. The input is only read and processed if the ready signal is high. Then we build a block which contains the signal processing which was presented in section \ref{fpga:polyphase}. The Block then throws out the wavelet coefficients and also the ready signal for further processing. In a next stage a block for inverse transformation is used to recover the input signal.
%In this block we then implement the Wavelet Transformation with, in our case, the Haar Wavelet. Another goal was to create a structure to implement different wavelet transformations later. In this way of implementation  it should be possible to implement transformations with different wavelets in the same block (Picture \ref{fpga:haar_inv_haar}). 
%
%\begin{figure}[h]
%	\includegraphics[width=0.49\textwidth]{images/haar.pdf}
%	\includegraphics[width=0.49\textwidth]{images/inv_haar.pdf}
%	\caption{Haar und inverse Haar transformation \label{fpga:haar_inv_haar}}
%\end{figure}

%\begin{figure}[h!]
%	\centering
%	\begin{subfigure}[b]{\linewidth}
%		\centering
%		\includegraphics[width=0.49\textwidth]{images/haar.pdf}
%		\caption{Haar}
%	\end{subfigure}
%	\begin{subfigure}[b]{\linewidth}
%		\centering
%		\includegraphics[width=0.49\textwidth]{images/inv_haar.pdf}
%		\caption{Inverse haar}
%	\end{subfigure}
%	\caption{Haar and inverse Haar transformation \label{fpga:haar_inv_haar}}
%\end{figure}

%In this picture it is also visible that for every two input samples we get two wavelet coefficients. This corresponds to the sub sampling into two streams. The ready signal gets also delayed to match the speed of the output coefficients. In the inverse Haar block the coefficients get reconstructed to the original input stream.







\section{Conclusion}
\rhead{Conclusion}

In our view this project was a success. We were able to use some of the knowledge gained in this course to implement a hardware version of a wavelet transformation.

All Codes (VHDL, MATLAB) are stored in the github repository belonging to this book. \cite{fpga:gitrepo-wavelets}

\printbibliography[heading=subbibliography]
\end{refsection}
